"""Script generation engine using LLM.

This module provides LLM-powered script generation for sequencing QC tasks.
The LLM generates Python or bash scripts based on experiment understanding.
"""

import hashlib
import json
import logging
from datetime import datetime
from enum import Enum
from typing import Any

from pydantic import BaseModel, Field

from aco.engine.gemini import GeminiClient, get_gemini_client
from aco.engine.models import ExperimentUnderstanding

logger = logging.getLogger(__name__)


class ScriptType(str, Enum):
    """Types of scripts that can be generated."""
    
    PYTHON = "python"
    BASH = "bash"
    R = "r"


class ScriptCategory(str, Enum):
    """Categories of QC scripts."""
    
    PARSE_ASSAY = "parse_assay"  # Barcode validation, read structure
    SEQUENCING_HEALTH = "sequencing_health"  # Quality metrics, base diversity
    QC_METRICS = "qc_metrics"  # Knee plots, hashtag profiles
    DATA_EXTRACTION = "data_extraction"  # Extract statistics from files
    CUSTOM = "custom"


class GeneratedScript(BaseModel):
    """A script generated by the LLM."""
    
    name: str = Field(..., description="Script filename")
    category: ScriptCategory = Field(..., description="Script category")
    script_type: ScriptType = Field(..., description="Script language")
    description: str = Field(..., description="What the script does")
    code: str = Field(default="", description="The script code (leave empty for plan)")
    dependencies: list[str] = Field(
        default_factory=list, description="Required packages/tools"
    )
    input_files: list[str] = Field(
        default_factory=list, description="Expected input files"
    )
    output_files: list[str] = Field(
        default_factory=list, description="Files the script will create"
    )
    estimated_runtime: str | None = Field(
        default=None, description="Estimated runtime"
    )
    requires_approval: bool = Field(
        default=True, description="Whether user approval is needed before running"
    )


class PlannedScript(BaseModel):
    """A script planned by the LLM (without code)."""
    
    name: str = Field(..., description="Script filename")
    category: ScriptCategory = Field(..., description="Script category")
    script_type: ScriptType = Field(..., description="Script language")
    description: str = Field(..., description="What the script does")
    dependencies: list[str] = Field(
        default_factory=list, description="Required packages/tools"
    )
    input_patterns: list[str] = Field(
        default_factory=list, description="Input file patterns (use globs like *.fastq.gz, not full paths)"
    )
    output_files: list[str] = Field(
        default_factory=list, description="Files the script will create (just filenames)"
    )
    estimated_runtime: str | None = Field(
        default=None, description="Estimated runtime"
    )
    requires_approval: bool = Field(
        default=True, description="Whether user approval is needed before running"
    )


class ScriptPlanSchema(BaseModel):
    """Schema for generating script plans (uses PlannedScript)."""
    
    manifest_id: str = Field(..., description="Associated manifest ID")
    scripts: list[PlannedScript] = Field(
        default_factory=list, description="Scripts to generate"
    )
    execution_order: list[str] = Field(
        default_factory=list, description="Order to run scripts (by name)"
    )
    total_estimated_runtime: str | None = Field(
        default=None, description="Total estimated runtime"
    )


class ScriptPlan(BaseModel):
    """A plan for scripts to generate and execute (includes code field)."""
    
    manifest_id: str = Field(..., description="Associated manifest ID")
    scripts: list[GeneratedScript] = Field(
        default_factory=list, description="Scripts to generate"
    )
    execution_order: list[str] = Field(
        default_factory=list, description="Order to run scripts (by name)"
    )
    total_estimated_runtime: str | None = Field(
        default=None, description="Total estimated runtime"
    )
    generated_at: datetime = Field(default_factory=datetime.now)
    is_approved: bool = Field(default=False)


# Check dependency availability
def check_dependencies(dependencies: list[str]) -> dict[str, bool]:
    import shutil
    return {dep: shutil.which(dep) is not None for dep in dependencies}


class ExecutionResult(BaseModel):
    """Result of script execution."""
    
    script_name: str = Field(..., description="Name of the script that was run")
    success: bool = Field(..., description="Whether execution succeeded")
    exit_code: int = Field(..., description="Process exit code")
    stdout: str = Field(default="", description="Standard output")
    stderr: str = Field(default="", description="Standard error")
    duration_seconds: float = Field(..., description="Execution time in seconds")
    started_at: datetime = Field(default_factory=datetime.now)
    completed_at: datetime | None = Field(default=None)
    error_message: str | None = Field(default=None, description="Error message if failed")
    output_files: list[str] = Field(
        default_factory=list, description="Files created by the script"
    )

    class Config:
        arbitrary_types_allowed = True


class ExecutionConfig(BaseModel):
    """Configuration for script execution."""
    
    timeout_seconds: int = Field(default=300, description="Max execution time")
    capture_output: bool = Field(default=True, description="Capture stdout/stderr")
    working_directory: str | None = Field(default=None, description="Working directory")
    environment: dict[str, str] = Field(
        default_factory=dict, description="Additional env vars"
    )
    python_executable: str = Field(
        default="python3", description="Python interpreter path"
    )


SCRIPT_GENERATION_SYSTEM = """You are an expert bioinformatics programmer specializing in sequencing QC pipelines.
Your role is to generate production-quality scripts that:
1. Are well-documented with clear comments
2. Handle errors gracefully
3. Produce structured output (JSON, CSV) for downstream processing
4. Are efficient and avoid unnecessary computation
5. Use standard bioinformatics libraries (pysam, scanpy, pandas, etc.)

When generating scripts:
- Always validate input files exist before processing
- Use logging for progress tracking
- Output results to specified output directory
- Include a main() function with proper argument parsing
- Generate scripts that can run independently
"""


SCRIPT_PLAN_PROMPT = """Based on the following experiment understanding, generate a plan for QC scripts.

# Experiment Understanding

{understanding_json}

# Available Files (sample)

{file_list}

# Instructions

Generate a list of scripts that will:
1. **Parse/Validate Assay**: If single-cell, validate barcode structure against whitelists
2. **Assess Sequencing Health**: Quality scores, base composition, mapping rates
3. **Generate QC Metrics**: Knee plots, UMI counts, gene detection rates

For each script, specify:
- Name, category, and script type (prefer Python)
- Clear description of purpose
- Required dependencies (package names only)
- Input patterns using GLOB SYNTAX (e.g. "gex_fastq/*_R1_*.fastq.gz", NOT full paths)
- Output files (just filenames, not full paths)
- Execution order

**CRITICAL**: Keep input_patterns SHORT using glob patterns. Do NOT list individual files.
Focus on scripts that can actually be run with the available files.
Prioritize essential QC checks over nice-to-haves. Limit to 3-5 scripts maximum.
"""


def _plan_signature(plan: ScriptPlan) -> str:
    """Return a stable semantic signature for comparing script plans."""
    scripts_data = []
    for s in plan.scripts:
        scripts_data.append({
            "name": s.name,
            "category": s.category.value if hasattr(s.category, "value") else s.category,
            "script_type": s.script_type.value if hasattr(s.script_type, "value") else s.script_type,
            "description": s.description,
            "dependencies": s.dependencies,
            "input_files": s.input_files,
            "output_files": s.output_files,
            "estimated_runtime": s.estimated_runtime,
            "requires_approval": s.requires_approval,
        })

    payload = {
        "scripts": scripts_data,
        "execution_order": plan.execution_order,
        "total_estimated_runtime": plan.total_estimated_runtime,
    }
    blob = json.dumps(payload, sort_keys=True, default=str)
    return hashlib.sha256(blob.encode("utf-8")).hexdigest()


def plans_equivalent(plan_a: ScriptPlan, plan_b: ScriptPlan) -> bool:
    """Return True if two plans are semantically identical."""
    return _plan_signature(plan_a) == _plan_signature(plan_b)


def summarize_plan_changes(
    old_plan: ScriptPlan,
    new_plan: ScriptPlan,
) -> dict[str, Any]:
    """Summarize script-level and ordering changes between two plans."""
    old_by_name = {s.name: s for s in old_plan.scripts}
    new_by_name = {s.name: s for s in new_plan.scripts}

    old_names = set(old_by_name.keys())
    new_names = set(new_by_name.keys())

    added_scripts = sorted(new_names - old_names)
    removed_scripts = sorted(old_names - new_names)

    modified_scripts: list[dict[str, Any]] = []
    common_names = sorted(old_names & new_names)
    for name in common_names:
        old_script = old_by_name[name]
        new_script = new_by_name[name]
        changed_fields: list[str] = []

        if old_script.category != new_script.category:
            changed_fields.append("category")
        if old_script.script_type != new_script.script_type:
            changed_fields.append("script_type")
        if old_script.description != new_script.description:
            changed_fields.append("description")
        if old_script.dependencies != new_script.dependencies:
            changed_fields.append("dependencies")
        if old_script.input_files != new_script.input_files:
            changed_fields.append("input_files")
        if old_script.output_files != new_script.output_files:
            changed_fields.append("output_files")
        if old_script.estimated_runtime != new_script.estimated_runtime:
            changed_fields.append("estimated_runtime")
        if old_script.requires_approval != new_script.requires_approval:
            changed_fields.append("requires_approval")

        if changed_fields:
            modified_scripts.append(
                {"name": name, "changed_fields": changed_fields}
            )

    execution_order_changed = old_plan.execution_order != new_plan.execution_order
    total_runtime_changed = (
        old_plan.total_estimated_runtime != new_plan.total_estimated_runtime
    )

    return {
        "added_scripts": added_scripts,
        "removed_scripts": removed_scripts,
        "modified_scripts": modified_scripts,
        "execution_order_changed": execution_order_changed,
        "old_execution_order": old_plan.execution_order,
        "new_execution_order": new_plan.execution_order,
        "total_estimated_runtime_changed": total_runtime_changed,
        "old_total_estimated_runtime": old_plan.total_estimated_runtime,
        "new_total_estimated_runtime": new_plan.total_estimated_runtime,
    }


def format_plan_change_summary(change_summary: dict[str, Any]) -> str:
    """Format a plan-change summary as markdown for chat display."""
    lines: list[str] = ["### Plan Changes"]

    added = change_summary.get("added_scripts", [])
    removed = change_summary.get("removed_scripts", [])
    modified = change_summary.get("modified_scripts", [])
    order_changed = bool(change_summary.get("execution_order_changed"))
    runtime_changed = bool(change_summary.get("total_estimated_runtime_changed"))

    if added:
        lines.append(f"- Added scripts: {', '.join(added)}")
    if removed:
        lines.append(f"- Removed scripts: {', '.join(removed)}")
    if modified:
        changed_desc = ", ".join(
            f"{m['name']} ({', '.join(m['changed_fields'])})" for m in modified
        )
        lines.append(f"- Modified scripts: {changed_desc}")
    if order_changed:
        old_order = change_summary.get("old_execution_order", [])
        new_order = change_summary.get("new_execution_order", [])
        lines.append(
            "- Execution order changed: "
            f"{' -> '.join(old_order) if old_order else '(none)'} => "
            f"{' -> '.join(new_order) if new_order else '(none)'}"
        )
    if runtime_changed:
        old_runtime = change_summary.get("old_total_estimated_runtime")
        new_runtime = change_summary.get("new_total_estimated_runtime")
        lines.append(
            f"- Total estimated runtime changed: {old_runtime or '(unset)'} => "
            f"{new_runtime or '(unset)'}"
        )

    if len(lines) == 1:
        lines.append("- No effective script-level changes detected.")

    return "\n".join(lines)


SCRIPT_CODE_PROMPT = """Generate the complete code for the following script:

# Script Specification
Name: {script_name}
Category: {category}
Type: {script_type}
Description: {description}

# Experiment Context
{understanding_summary}

# Input Files
{input_files}

# Output Directory
{output_dir}

# Expected Outputs
{output_files}

# Dependencies Available
{dependencies}

# Instructions

Generate a complete, runnable script that:
1. Parses command-line arguments for input/output paths
2. Validates inputs exist
3. Performs the analysis described
4. Saves results to the output directory
5. Prints a summary to stdout
6. Returns exit code 0 on success, non-zero on failure

Include comprehensive error handling and logging.
The script should be self-contained and ready to run.

IMPORTANT: Output ONLY the script code. Do not include any explanatory text before or after the code.
Start directly with the shebang (#!/usr/bin/env python3) or imports.
Do not use markdown code blocks - just output the raw script.
"""


REFERENCE_SCRIPT_ADDENDUM = """

# Reference Script

An existing script has been uploaded via the Gemini Files API as a reference.
Use its structure, coding patterns, argument parsing style, and conventions as
a starting point. Adapt it for the new task described above while preserving
useful patterns from the reference.

Reference file: {reference_name}
"""

# Extensions considered as scripts when scanning descriptions
_SCRIPT_FILENAME_RE_PATTERN = r"""(?:['"`])([A-Za-z0-9_\-]+\.(?:py|R|r|sh|nf|wdl))(?:['"`])"""


def detect_referenced_scripts(
    description: str,
    search_dirs: list[str] | None = None,
) -> list[str]:
    """Parse a script description for mentions of existing script filenames
    and return the paths of any that are found on disk.

    The function looks for patterns like ``'feature_barcode_detector.py'``
    or ``"qc_check.R"`` in *description*, then searches *search_dirs*
    recursively for matching files.

    Args:
        description: The script description text to scan.
        search_dirs: Directories to search for the referenced files.

    Returns:
        List of absolute paths to scripts found on disk.
    """
    import re
    from pathlib import Path as _Path

    if not description or not search_dirs:
        return []

    # Extract candidate filenames from the description
    candidates: set[str] = set()

    # Quoted filenames: 'script.py', "script.py", `script.py`
    for match in re.finditer(_SCRIPT_FILENAME_RE_PATTERN, description):
        candidates.add(match.group(1))

    # Unquoted filenames with extensions
    for match in re.finditer(
        r"\b([A-Za-z0-9_\-]+\.(?:py|R|r|sh))\b", description
    ):
        candidates.add(match.group(1))

    if not candidates:
        return []

    logger.debug(
        "Detected script references in description: %s", candidates
    )

    # Search the directories for matching files
    found: list[str] = []
    seen: set[str] = set()
    for dir_path in search_dirs:
        d = _Path(dir_path)
        if not d.exists():
            continue
        for candidate in candidates:
            for hit in d.rglob(candidate):
                # Skip __pycache__, hidden dirs, etc.
                if any(
                    part.startswith(".") or part == "__pycache__"
                    for part in hit.parts
                ):
                    continue
                abs_path = str(hit.resolve())
                if abs_path not in seen:
                    seen.add(abs_path)
                    found.append(abs_path)

    if found:
        logger.info(
            "Auto-detected %d reference script(s) from description: %s",
            len(found),
            [_Path(p).name for p in found],
        )

    return found


async def generate_script_plan(
    understanding: ExperimentUnderstanding,
    file_list: list[str],
    client: GeminiClient | None = None,
) -> ScriptPlan:
    """Generate a plan for QC scripts based on experiment understanding.
    
    Args:
        understanding: The experiment understanding
        file_list: List of available file paths
        client: Optional Gemini client
    
    Returns:
        ScriptPlan with scripts to generate
    """
    if client is None:
        client = get_gemini_client()
    
    # Build the prompt - summarize files by directory instead of listing all
    understanding_json = understanding.model_dump_json(indent=2)
    
    # Summarize files by directory to keep response small
    from collections import defaultdict
    from pathlib import Path as PPath
    dir_summary = defaultdict(list)
    for f in file_list:
        p = PPath(f)
        dir_summary[str(p.parent)].append(p.name)
    
    file_summary_lines = []
    for dir_path, files in list(dir_summary.items())[:5]:  # Max 5 directories
        file_summary_lines.append(f"Directory: {dir_path}")
        # Show only 3 example files per directory
        for fname in files[:3]:
            file_summary_lines.append(f"  - {fname}")
        if len(files) > 3:
            file_summary_lines.append(f"  - ... and {len(files) - 3} more files")
    
    file_list_str = "\n".join(file_summary_lines)
    
    prompt = SCRIPT_PLAN_PROMPT.format(
        understanding_json=understanding_json,
        file_list=file_list_str,
    )
    
    # Use ScriptPlanSchema which explicitly excludes code field from scripts
    plan_schema = await client.generate_structured_async(
        prompt=prompt,
        response_schema=ScriptPlanSchema,
        system_instruction=SCRIPT_GENERATION_SYSTEM,
        temperature=0.3,
    )
    
    # Convert to full ScriptPlan (adding empty code fields)
    full_scripts = []
    for s in plan_schema.scripts:
        full_scripts.append(GeneratedScript(
            name=s.name,
            category=s.category,
            script_type=s.script_type,
            description=s.description,
            code="",  # Explicitly empty
            dependencies=s.dependencies,
            input_files=s.input_patterns,  # Map patterns to input_files
            output_files=s.output_files,
            estimated_runtime=s.estimated_runtime,
            requires_approval=s.requires_approval
        ))
        
    return ScriptPlan(
        manifest_id=plan_schema.manifest_id,
        scripts=full_scripts,
        execution_order=plan_schema.execution_order,
        total_estimated_runtime=plan_schema.total_estimated_runtime
    )


async def generate_script_code(
    script: GeneratedScript,
    understanding: ExperimentUnderstanding,
    output_dir: str,
    client: GeminiClient | None = None,
    reference_script_path: str | None = None,
    search_dirs: list[str] | None = None,
) -> str:
    """Generate the actual code for a script.
    
    Args:
        script: The script specification
        understanding: Experiment context
        output_dir: Where outputs should be saved
        client: Optional Gemini client
        reference_script_path: Optional explicit path to a reference script
            to upload via the Gemini Files API.
        search_dirs: Directories to search when auto-detecting referenced
            scripts from the script description. When provided and no
            explicit *reference_script_path* is given, the description is
            parsed for script filenames (e.g. ``'feature_barcode_detector.py'``)
            and any matches found on disk are uploaded automatically.
    
    Returns:
        The generated script code
    """
    if client is None:
        client = get_gemini_client()
    
    prompt = SCRIPT_CODE_PROMPT.format(
        script_name=script.name,
        category=script.category.value,
        script_type=script.script_type.value,
        description=script.description,
        understanding_summary=understanding.summary,
        input_files="\n".join(f"- {f}" for f in script.input_files),
        output_dir=output_dir,
        output_files="\n".join(f"- {f}" for f in script.output_files),
        dependencies=", ".join(script.dependencies),
    )

    from pathlib import Path as _Path

    # Collect reference file paths to upload
    ref_paths: list[str] = []

    # 1. Explicit reference takes priority
    if reference_script_path and _Path(reference_script_path).exists():
        ref_paths.append(reference_script_path)

    # 2. Auto-detect from the script description when no explicit ref
    if not ref_paths and search_dirs:
        ref_paths = detect_referenced_scripts(
            script.description, search_dirs
        )

    if ref_paths:
        ref_names = ", ".join(_Path(p).name for p in ref_paths)
        prompt += REFERENCE_SCRIPT_ADDENDUM.format(reference_name=ref_names)
        logger.info(
            "Generating code for %s with %d reference script(s): %s",
            script.name,
            len(ref_paths),
            ref_names,
        )

        response = await client.generate_with_files_async(
            prompt=prompt,
            file_paths=ref_paths,
            system_instruction=SCRIPT_GENERATION_SYSTEM,
            temperature=0.2,
            max_output_tokens=16384,
        )
    else:
        # Standard generation without reference files
        response = await client.generate_async(
            prompt=prompt,
            system_instruction=SCRIPT_GENERATION_SYSTEM,
            temperature=0.2,  # Lower temp for code
            max_output_tokens=16384,  # Higher limit for complete scripts
        )
    
    # Extract code from markdown code blocks
    code = extract_code_from_response(response, script.script_type)
    
    # Validate that the code appears complete
    code = validate_script_code(code, script.script_type)
    
    return code


def extract_code_from_response(response: str, script_type: ScriptType) -> str:
    """Extract code from LLM response, handling markdown blocks and text preambles.
    
    Args:
        response: Raw LLM response
        script_type: Expected script type
        
    Returns:
        Extracted code
    """
    import re
    
    response = response.strip()
    
    # Try to find code block with language specifier
    lang_patterns = {
        ScriptType.PYTHON: r"```(?:python|py)\n(.*?)```",
        ScriptType.BASH: r"```(?:bash|sh)\n(.*?)```",
        ScriptType.R: r"```(?:r|R)\n(.*?)```",
    }
    
    pattern = lang_patterns.get(script_type)
    if pattern:
        match = re.search(pattern, response, re.DOTALL)
        if match:
            return match.group(1).strip()
    
    # Try generic code block
    match = re.search(r"```\w*\n(.*?)```", response, re.DOTALL)
    if match:
        return match.group(1).strip()
    
    # If response starts with ```, use original logic
    if response.startswith("```"):
        lines = response.split("\n")
        # Find the closing ```
        end_idx = len(lines)
        for i in range(len(lines) - 1, 0, -1):
            if lines[i].strip() == "```":
                end_idx = i
                break
        return "\n".join(lines[1:end_idx])
    
    # No code block found, check if it looks like code already
    # Python scripts typically start with imports, comments, or shebang
    first_line = response.split("\n")[0].strip() if response else ""
    if (first_line.startswith("#") or 
        first_line.startswith("import ") or 
        first_line.startswith("from ") or
        first_line.startswith("#!/")):
        return response
    
    # Response might be text description followed by code without proper block
    # Look for shebang or import as code start
    lines = response.split("\n")
    for i, line in enumerate(lines):
        if (line.strip().startswith("#!/") or 
            line.strip().startswith("import ") or
            line.strip().startswith("from ")):
            return "\n".join(lines[i:])
    
    # Return as-is (validation will catch if it's not valid code)
    return response


def validate_script_code(code: str, script_type: ScriptType) -> str:
    """Validate that generated code appears complete.
    
    Args:
        code: The generated code
        script_type: Type of script
        
    Returns:
        The validated code
        
    Raises:
        ValueError: If the code appears truncated or incomplete
    """
    if not code or len(code.strip()) < 50:
        raise ValueError("Generated code is too short - likely truncated")
    
    lines = code.strip().split("\n")
    
    # A valid script should have a reasonable number of lines
    if len(lines) < 20:
        raise ValueError(
            f"Generated code has only {len(lines)} lines - likely truncated. "
            "A complete script should have at least 20 lines."
        )
    
    if script_type == ScriptType.PYTHON:
        # Check for common signs of truncation
        last_line = lines[-1].strip() if lines else ""
        
        # Check if last line looks incomplete
        incomplete_indicators = [
            last_line.endswith("("),
            last_line.endswith(","),
            last_line.endswith("="),
            last_line.endswith(":"),
            "logging.critical(" in last_line and not last_line.endswith(")"),
            last_line.startswith("#") and len(last_line) < 10,  # Truncated comment
        ]
        
        if any(incomplete_indicators):
            raise ValueError(
                f"Generated Python code appears truncated. Last line: '{last_line[:50]}...'. "
                "Try regenerating the script."
            )
        
        # Check for balanced parentheses (basic check)
        open_parens = code.count("(") - code.count(")")
        if open_parens > 5:  # Allow some tolerance
            raise ValueError(
                f"Generated Python code has unbalanced parentheses ({open_parens} unclosed). "
                "Code may be truncated."
            )
    
    return code


def get_script_extension(script_type: ScriptType) -> str:
    """Get the file extension for a script type."""
    return {
        ScriptType.PYTHON: ".py",
        ScriptType.BASH: ".sh",
        ScriptType.R: ".R",
    }[script_type]


# ---------------------------------------------------------------------------
# Plan refinement
# ---------------------------------------------------------------------------

REFINE_PLAN_PROMPT = """You are refining an existing script plan based on user feedback.

# Current Script Plan

{plan_json}

# Experiment Context

{understanding_summary}

# User Feedback

{feedback}

# Instructions

Based on the user's feedback, modify the script plan accordingly. You may:
- Add new scripts
- Remove scripts
- Modify existing script descriptions, dependencies, inputs, or outputs
- Change execution order

Return the COMPLETE updated plan (not just the changes).
Keep input_patterns as glob patterns. Limit to 3-5 scripts.
"""


async def refine_script_plan(
    plan: ScriptPlan,
    feedback: str,
    understanding: ExperimentUnderstanding,
    client: GeminiClient | None = None,
) -> tuple[ScriptPlan, str]:
    """Refine a script plan based on user feedback.

    Args:
        plan: The current script plan
        feedback: User's feedback/instructions
        understanding: Experiment context
        client: Optional Gemini client

    Returns:
        Tuple of (updated_plan, response_message)
    """
    if client is None:
        client = get_gemini_client()

    # Build compact plan JSON (exclude code to save tokens)
    plan_data = []
    for s in plan.scripts:
        plan_data.append({
            "name": s.name,
            "category": s.category.value if hasattr(s.category, "value") else s.category,
            "script_type": s.script_type.value if hasattr(s.script_type, "value") else s.script_type,
            "description": s.description,
            "dependencies": s.dependencies,
            "input_files": s.input_files,
            "output_files": s.output_files,
        })

    plan_json = json.dumps(plan_data, indent=2)
    understanding_summary = understanding.summary[:500]

    async def _run_refine_pass(refinement_feedback: str, temperature: float) -> ScriptPlan:
        prompt = REFINE_PLAN_PROMPT.format(
            plan_json=plan_json,
            understanding_summary=understanding_summary,
            feedback=refinement_feedback,
        )

        refined = await client.generate_structured_async(
            prompt=prompt,
            response_schema=ScriptPlanSchema,
            system_instruction=SCRIPT_GENERATION_SYSTEM,
            temperature=temperature,
        )

        full_scripts = []
        for s in refined.scripts:
            full_scripts.append(GeneratedScript(
                name=s.name,
                category=s.category,
                script_type=s.script_type,
                description=s.description,
                code="",
                dependencies=s.dependencies,
                input_files=s.input_patterns,
                output_files=s.output_files,
                estimated_runtime=s.estimated_runtime,
                requires_approval=s.requires_approval,
            ))

        return ScriptPlan(
            manifest_id=plan.manifest_id,
            scripts=full_scripts,
            execution_order=refined.execution_order,
            total_estimated_runtime=refined.total_estimated_runtime,
        )

    updated_plan = await _run_refine_pass(feedback, temperature=0.3)

    # If refinement returns the same plan, run a forced retry that must apply edits.
    if plans_equivalent(plan, updated_plan):
        forced_feedback = (
            f"{feedback}\n\n"
            "IMPORTANT: Your previous output made no effective changes to the plan. "
            "Apply the user's request with concrete edits (add/remove/rename scripts, "
            "or update script descriptions/dependencies/inputs/outputs/execution order). "
            "Do not return a no-op plan."
        )
        updated_plan = await _run_refine_pass(forced_feedback, temperature=0.4)

    if plans_equivalent(plan, updated_plan):
        return plan, "No effective plan changes were applied from this feedback."

    change_summary = summarize_plan_changes(plan, updated_plan)
    return updated_plan, format_plan_change_summary(change_summary)


# ---------------------------------------------------------------------------
# Pre-existing script utilities
# ---------------------------------------------------------------------------

def read_existing_script(script_path: str) -> str:
    """Read the contents of an existing script file.

    Args:
        script_path: Path to the script file

    Returns:
        The file contents as a string

    Raises:
        FileNotFoundError: If the file doesn't exist
    """
    from pathlib import Path
    p = Path(script_path)
    if not p.exists():
        raise FileNotFoundError(f"Script not found: {script_path}")
    return p.read_text()


UPDATE_SCRIPT_PROMPT = """You are updating an existing bioinformatics script based on user instructions.

# Current Script Code

```
{current_code}
```

# Experiment Context

{understanding_summary}

# User Instructions

{instructions}

# Rules

1. Preserve the overall structure and logic of the script.
2. Update input paths, output paths, and parameters as instructed.
3. Ensure the script remains runnable and well-structured.
4. Output ONLY the complete updated script code, no explanations.
"""


async def update_existing_script(
    script_path: str,
    understanding: ExperimentUnderstanding,
    instructions: str,
    client: GeminiClient | None = None,
) -> str:
    """Read an existing script and update it based on instructions.

    Args:
        script_path: Path to the existing script
        understanding: Experiment context
        instructions: User instructions for updates
        client: Optional Gemini client

    Returns:
        The updated script code
    """
    if client is None:
        client = get_gemini_client()

    current_code = read_existing_script(script_path)

    prompt = UPDATE_SCRIPT_PROMPT.format(
        current_code=current_code,
        understanding_summary=understanding.summary[:500],
        instructions=instructions,
    )

    response = await client.generate_async(
        prompt=prompt,
        system_instruction=SCRIPT_GENERATION_SYSTEM,
        temperature=0.2,
        max_output_tokens=16384,
    )

    # Extract code from response
    code = extract_code_from_response(response, ScriptType.PYTHON)
    return code
